- [结题报告](#结题报告)
  - [项目简介](#项目简介)
  - [立项依据](#立项依据)
  - [设计与实现](#设计与实现)
    - [整体架构](#整体架构)
    - [yijinjing](#yijinjing)
      - [为什么选择易筋经](#为什么选择易筋经)
      - [yijinjing架构一览](#yijinjing架构一览)
      - [yijinjing性能测试](#yijinjing性能测试)
        - [使用C++向yijinjing连续写入1000条数据](#使用C向yijinjing连续写入1000条数据)
        - [使用python向yijinjing逐次写入数据](#使用python向yijinjing逐次写入数据)
        - [使用python向MySQL逐次写入数据](#使用python向MySQL逐次写入数据)
      - [接口实现](#接口实现)
    - [Rain](#Rain)
      - [需求](#需求)
      - [rain](#rain)
  - [环境配置与使用方法](#环境配置与使用方法)
    - [注意事项](#注意事项)
    - [final文件夹下内容简介](#final文件夹下内容简介)
    - [使用方法](#使用方法)
      - [简单测试](#简单测试)
      - [多机测试](#多机测试)
  - [基于平台实现的应用: 量化交易工具](#基于平台实现的应用-量化交易工具)
    - [整体架构](#整体架构-1)
    - [量化交易简介](#量化交易简介)
    - [均线策略简介](#均线策略简介)
    - [数据获取](#数据获取)
    - [结果展示](#结果展示)
  - [改进、展望与总结](#改进展望与总结)
    - [目前项目存在的问题](#目前项目存在的问题)
    - [展望与总结](#展望与总结)

# 结题报告

##  项目简介

本项目搭建了一个分布式时序计算平台，并为该平台编写了一个分布式的股票监视预测交易的模拟程序。

我们将一个分布式计算框架Rain，与一个数据库yijinjing结合起来搭建此平台。利用rain分布式特性，我们可以定义多个任务，并将任务分发给不同的节点，使不同节点监控不同股票，实时地分析股票数据并发出交易信息。同时，由于yijinjing数据库读写速度极快，且提供快速将数据同步至磁盘的功能，这使得在高频量化交易中既可以实时分析数据以最短的延迟发出交易信息，又可以以极低的开销将数据存入磁盘，便于盘后分析与预测算法的改进。

总体来说，我们在量化交易中提供了一种低成本高吞吐量（分布式）的方案，同时利用数据库也平衡了量化交易中实时性与数据可持久化两者之间的矛盾。

##  立项依据

时序数据是同一统一指标按时间顺序记录的数据列。在同一数据列中的各个数据是同口径的，具有可比性。时序数据可以是时期数，也可以时点数。时间序列分析的目的是通过找出样本内时间序列的统计特性和发展规律性，构建时间序列模型，进行样本外预测。利用好时序数据可以揭示可操作的趋势，模式，可变性等重要参数。

可见，快速地处理时序数据并从中获取信息可以产生巨大的价值与能量，对时序数据高速有效地处理的需求如今也在逐渐增大。

超级计算在现代科学中发挥着重要的作用，例如天文、化学等很多领域的研究都需要进行繁重的计算任务来模拟行为或者搜索结果。然而，超级计算成本非常高昂，这迫使许多实验只能“从简”，妨碍了科学的发展。

分布式计算是超级计算的一种很好的替代方法。对于一些大型的计算项目，可以由服务器分成很多小的计算任务，分发给与服务器相连的节点，同时计算，再将结果返回，由服务器整合。这样虽然速度比超级计算慢，但相比于传统单机运行，速度大大提升，而且成本较超级计算而言微乎其微。

所以我们使用分布式计算框架Rain结合时序数据库yijinjing搭建分布式时序计算平台。

##  设计与实现

### 整体架构
此项目的整体架构如下。在分布式的层面上，架构分为主机和节点，主机控制节点，主机生成任务并以一定的方式分发给节点，由节点进行主要的运算任务。

在每个节点中，我们为节点任务的运行提供了相应的数据库接口。当任务有对中间数据持久化的需求而又不想在磁盘读写上浪费太多时间时，数据库便提供了一种行之有效的方案，满足用户的需求。

在分布式框架的选择上，我们使用了rain，一个轻量级的框架。在数据库的使用选择上，我们选择了yijinjing，一个流式的时序内存数据库，其在多次少量的数据写入与低延时的数据可持久化上有着无与伦比的优势。

![此处应该是架构图片](files/frame.svg)

分布式框架只支持使用Python作为定义任务的语言，而python在进程通信中所能提供的功能十分有限。我们将读写数据库的接口封装为了动态库文件，并利用python相应的库ctypes调用从而实现与数据库的交互，因此在这个项目中节点任务与数据库的交互的性能有一定影响。我们也在努力寻求更加高效的进程通信与交互方式。

###  yijinjing

#### 为什么选择易筋经

市场上主流的数据库，第一优先的核心功能是查询，在海量数据中快速定位到查询的那一条。数据结构在内存中的设计更像是一个巨大的哈希表，这注定相邻数据不会存在连续内存区域，访问和写入数据都存在一定的开销。

而在金融实时交易场景下，以最快的速度处理当前最新的行情或是成交数据，才是第一优先需要考虑的，如果你同时需要保存这些数据，那么传统数据库那些难以割舍的写入耗时就会让你泪流满面。

你可能会考虑多开几个线程，用专门的线程来负责存储。这样看似在功能上实现了数据保存，但是系统内因此产生的诸多内存拷贝、网络冗余请求都会在不知不觉中加重你的延迟，并且臃肿的架构也会让你在数据种类增多时难以维护。项目本身的易维护性与美观性也大打折扣。

而我们这次设计的是面向时间序列的分布式计算平台，数据库部分的目的是在大量时间序列数据输入的情况下，把数据存储下来，便于后续的分析。

综上所述，我们选择使用开源项目易筋经数据库。易筋经使用mmap作为底层存储机制，本质上是通过操作系统 kernel 后台进程异步完成内存内容到磁盘文件的同步操作，意味着它赋予了一种在操作内存同时以零延时来操作磁盘文件的能力，使得我们无需担心数据持久化方面的耗时，帮助我们同时完成通信和存储这两个重要任务，这是使用 mmap 方法的精髓所在。

#### yijinjing架构一览

在文件层面上，易筋经包含以下内容: 
```
+ libreader.so libwriter.so #数据库读写接口
+ yjj_page_service  #二进制文件，启动yijinjing
+ libjournal.so	libpaged.so #yijinjing运行辅助文件
+ page_engine.json  #配置文件
```

运行yjj_page_service，它会读取配置文件，并在配置文件指定的目录下写入日志和存放数据库相关文件，然后创建一个数据库进程，接收由调用接口产生的读写请求，并对数据库做出相应的读写操作。


在内部结构上，一个数据库进程维护多个Journal。每个Journal由多个page组成，默认每个page为128MB。每个page包含多个frame，每个frame便储存一条数据。您可以在一个frame中存储一条无类型数据，并同时指定其长度与数据类型。

为从而保障它的进程/线程安全，规定一个 Journal 只能有一个写入线程。写入者 Writer 在写入内容时，每一次都是通过一个原子操作在 Journal 中形成一个 Frame。Frame 结构包含一个头部（Header）信息和数据部分，Header 中定义跟该次写入有关的一些元信息，例如写入时间，数据类型等。数据部分的格式由数据类型定义，访问者利用元信息中的数据类型即可调用对应的解码器。这样，每一个 Journal 都可以看成由无数相邻 Frame 所组成的流式数据链。但是由于底层使用 mmap 进行磁盘回写，而 mmap 本身只能创建定长文件，所以我们定义每次 mmap 创建的文件为 Journal 的一个页（Page），结构如下：

![](files/yijinjing1.jpg)

每个 Page 是一个定长的文件（目前在功夫中我们定义为 128MB 大小），易筋经会根据使用者需要进行拼接，使得访问者透明的得到一个无限长（当然，真正的容量上限取决于磁盘大小）的 Journal：

![](files/yijinjing2.jpg)

在每次读写进行到 Page 边界的时候，易筋经需要小心进行一系列细节操作，使得访问者可以无缝的切换到下一个 Page，涉及到诸如调用 mmap 创建新的内存映射文件，对内存映射文件进行预处理等，这些操作往往相当耗时（毫秒级别），我们无法在实时读写数据时承受这个负担。易筋经的解决方案，是在后台启动并维护一个 PageEngine 进程，该进程负责提前载入缓存一些备用 Page，在需要时便可以立刻交付使用。在这种结构设计下，由于我们是夸进程的申请、分配、释放资源，所以需要多做一些安保工作，确保资源不会泄漏。PageEngine 内部会小心的记录申请者的进程编号 pid ，定期查询客户进程是否仍然健康存在，发现僵尸进程则会对其申请的资源进行释放操作。


####  yijinjing性能测试

##### 使用C++向yijinjing连续写入1000条数据

使用C++和连续写入的方式可以将数据最快地写入yijinjing数据库。下图是测量连续写入1000条数据的时间，求出4000次测量的均值、方差、最小值、最大值、有效次数，整个测量过程重复10次的结果。可见，写入1000次平均耗时约为70000ns。

![Screenshot from 2019-07-04 21-52-55](files/c++_yijinjing.png)

##### 使用python向yijinjing逐次写入数据

下图是使用python逐次写入yijinjing，求出写入4000条数据的时间的平均值、方差、最小值、最大值。可见，每写入一条数据平均耗时约为0.6ms。

![Screenshot from 2019-07-04 22-16-44](files/python_yijinjing.png)

#####  使用python向MySQL逐次写入数据

下图是使用python逐次写入MySQL，求出写入4000条数据的时间的平均值。可见，每写入一条数据平均耗时7ms，远大于yijinjing的平均值0.6ms。

![Screenshot from 2019-07-04 21-47-21](files/python_mysql.png)

由上面三个测试可见，yijinjing数据库的写入速度远远快于常用的MySQL数据库。

#### 接口实现

Rain提供了python的接口，而易筋经本身是用C++编写的，要用Rain调用易筋经，需要编写一些基本接口。我们为此设计了基本的写入数据，读出数据，打印数据和把数据转化为.csv格式文件的API。

已实现部分：

```
def writeSingleData(data,msgType,jname)
def readSingleData(readtime,jname)
def readSingleMsgType(readtime,jname)
def printAllData(startTime,jname)
def convertAllToCSV(startTime,fileName,jname)
def readCSV(filename,jname)
def deleteJournal(dir,jname)
```

已设计但未实现部分：

```
def expireJournal(journalName)
def initJournal(dir,jname)
def expireJournalByIndex(index,journalName)
```

`data`是数据本体，`msgType`用来标记数据类型，`jname`指定把数据写入到哪一个`Journal`部分。一个`Journal`对应一次写入事件。调用`writeSingleData`时会将数据写入数据库，以二进制文件的形式保存，同时会返回一个时间戳，想要读取数据时可以通过时间戳来读取对应位置的数据或者打印从特定位置开始的所有数据。如果要进行数据的整体分析，提供了`converAllToCSV`接口，将指定Journal内从特定时间开始的数据全部转换为`.csv`格式，便于后续分析。

###  Rain

#### 需求

为了搭建一个实用的时序数据分析平台，就势必要减少处理数据的时间以提高数据可用性。金融领域中常使用高性能的设备以减少延时。鉴于其成本问题，分布式可为一个退而求其次的选择，这样可以在损失一点性能的区别下获得更大的成本优势。

#### rain

rain是一个分布式计算框架。在表层上，其主要由两个部分组成：一个叫rain的一体化静态链接二进制文件，和一个用于调用rain服务的python的库。前者由rust语言编写而成，rust语言的特点保障了rain工作的安全性、高效性与可靠性，后者由python构成，目的在于能使用户方便快捷地使用此分布式计算框架。

在底层上，rain的二进制文件包含了server，executor与governor三个主要组成部分。其中：

server是服务器节点，用于与其他计算节点通信，管理其余计算节点，并进行任务分配与调度，收集计算结果。

governor是计算节点的调控管理者，用于与服务器节点通信，接收服务器节点分配的任务与数据，生成executor执行这些任务，并将结果返回给服务器节点。

executor是在计算节点由governor生成的用于执行计算任务的部分。rain中内置了部分简单的executor用于简单测试功能（如将两个字符串合并），也支持使用python的通用executor，还提供了rust与c的库，以方便用户编写自己的专用executor。

由于rain将服务器功能与计算节点功能融合进了一个二进制文件中，则目标机器是服务器还是计算节点取决于如何执行rain。执行

```
./rain start --simple
```

会将server与governor都部署于本地机器上。执行

```
 rain start -S --governor-host-file=my_hosts
```
会将server部署于本地，从my_hosts文件中读取计算节点信息，并使用ssh连接计算节点。执行
```
rain governor <SERVER-ADDRESS>
```
会在本机上启动一个计算节点。它将尝试与server通信，从而接收数据与计算任务。
由于rain本身一体化的设置与便于使用的特性，对其进行使用与部署的便利性大大增强。

此外，rain本身提供了dashboard,可以用于实时监测任务执行情况,有利于用户有效找到性能瓶颈。

因此，rain作为一个轻量级的分布式计算框架，提供的pythonAPI易于用户的使用又便于在不改变原有代码的情况下，简单地嵌入程序以实现从单机到分布式的升级。而rust的内核又保证了计算的速度与系统的安全。同时基于启发式算法的任务调度器又保证了算力的充分利用。

##  环境配置与使用方法

###  注意事项

本项目有以下事项需要注意：

- 本项目主机与计算节点需要在 `/root`目录下工作，因此需保证主机与节点的root账号均可以使用，且节点允许ssh以root身份登录。

- 数据库的使用需要boost库。在ubuntu下，可以运行以下命令安装所需的库。

  ```
  apt-get install libboost-all-dev
  ```

### final文件夹下内容简介

在final文件夹下有以下文件：

- yjj_page_service : 此文件用于启动yijinjing数据库，直接运行后作为一个进程接收写入与读取请求。
- libreader.so libwriter.so : 此为读取写入数据库所提供的功能，以动态库的形式封装。可以使用c++调用，也可以使用python配合ctypes库调用从而对数据库进行读写。
- page_engine.json : 配置文件。配置数据库日志与数据库文件的路径，默认存在`/tmp`下。
- rain : 一个分布式框架，一个二进制文件。用于计算任务的分配，任务的控制运行与结果的收集。
- stock.py : 本次项目中的一个实例项目。此项目监视多支股票，多线程实时获取当前监视的股票数据，异步地将获取的数据存入数据库，通过均线策略分析股票数据，给出买入与卖出的建议。
- spiderfunc.py : 读写数据库所封装的python库。里面集成了数据库的的单条写入，按时间戳单独读出，导出数据库，删除数据库等功能，为用户的使用提供方便。
- libjournal.so	libpaged.so : 数据库使用的辅助二进制动态库。

###  使用方法

rain可以以server方式启动，此时rain所在机器为主机。也可以governor方式启动，此时rain所在机器为节点。

####  简单测试

如果想进行简单的测试，则主机与节点在同一台物理机器上，可以按以下方式操作:

1. 将final文件夹下所有内容拷贝至主机下`/root`中。

   ```
   cp final/* /root
   ```

2. 切换目录至```/root```，并使用```--simple```的方式启动rain。以下代码会在本地机器上创建server，并使用本地的一个核作为节点来运行程序。

   ```
   cd /root
   ./rain start --simple
   ```

3. 手动启动数据库。数据库会运行一个进程，监听并接收读写请求。

   ```
    ./yjj_page_service &
   ```

4. 使用python3运行测试stock.py文件。stock.py接受若干参数，其中:

   - `-s <sleep time>`或`--sleep-time=<sleep time>` : 睡眠时间。指定获取数据之间间隔的时间，单位为秒。默认为0.01s。
   - `-t <thread num>`或`--thread-num=<thread num>` : 线程数量。指定多线程获取数据时线程的数量。默认为3。
   - `-c <stock code>`或`--stock-code=<stock code>` : 指定要监听的股票代码。目前测试代码使用的数据来源为新浪股票API。新浪股票API支持从深圳证券交易所与上海证券交易所获取数据。`<stock code>`参数的正确示例如下:

   ```
    sh600000    #从上交所，代码为600000股票获取数据
    sh600001,sh600002   #从上交所获取两支股票，以逗号间隔
    sh123456,sz098765,sh246809  #从深交所，上交所获取三支股票，以逗号间隔
   ```

   以下均为正确运行stock.py的正确示例，python3可换成任意的python3.6解释器 :

   ```
    python3 stock.py -c sh600000
    python3 stock.py -c sh600000,sh600001,sh600002,sh600003 -s 1 
    python3 stock.py --stock-code=sh600000,sh600001,sh600002,sz123456 -s 0.01 -t 4
   ```

如果能正常运行，您将能看到以下结果 :

- 由于无法真实地发出交易信息，所有生成的交易信息保存在了`/root/ans.txt`中。
- 运行过程中，浏览器打开`127.0.0.1:7222`可以监视任务的运行情况。
- page_engine.json文件中指定的目录出现数据库文件。您可以通过一定的方式从中读取。

####  多机测试

首先对于主机:

1. 将final文件夹下所有内容拷贝至主机下`/root`中。

2. 切换目录至```/root```，以server方式启动rain。有以下两种启动方式。以下方式只会启动主机上的server，需要在节点显式地与主机建立联系。

   ```
    ./rain server &
   # only start server
   ```

   以下方式会在启动主机上server时，通过ssh连接节点，并以governor方式启动节点上的rain，控制节点与主机通信。```<host file name>```为一个文件，一行一个ip。

   ```
   ./rain start --governor-host-file=<host file name>
   # start server, also start governor on other nodes
   ```

对于节点:

1. 将final文件夹下所有内容拷贝至主机下`/root`中。

2. 切换目录至```/root```，若主机只启动了server，按照以下方式显式地连接主机。

   ```
   ./rain governor <server ip> [-p <port>]
   ```

3. 显式地启动节点上的数据库。

   ```
   ./yjj_page_service &
   ```

以上工作完成后，在主机直接运行stock.py文件，运行方式如上所述。

如果能正常运行，您将能看到以下结果 :

- 由于无法真实地发出交易信息，所有生成的交易信息保存在了各个节点的`/root/ans.txt`中。
- 运行过程中，在主机浏览器打开`127.0.0.1:7222`可以监视任务的运行情况。
- 在节点中page_engine.json文件中指定的目录出现数据库文件。您可以通过一定的方式从中读取。



## 基于平台实现的应用: 量化交易工具

我们为此项目编写了一个实际应用——一个自动化监视预测交易工具。该应用通过此分布式框架，监视多支股票，多线程实时获取当前监视的股票数据，异步地将获取的数据存入数据库，通过均线策略分析股票数据，给出买入与卖出的建议。

### 整体架构

stock.py主要包含以下内容:

1. 任务分配: 程序得到用户需要监视的股票池的时候，程序会将这些股票分成若干组，每组5支股票。每一个任务监视一组股票，这样就可以定义若干个任务。任务被提交给rain的任务调度器，由任务调度器根据计算资源利用情况将任务分配给节点，开始分布式地监视股票。
2. 数据获取: 本程序从新浪股票API获取数据。利用线程池并发地获取数据。
3. 数据存取: 通过已经实现的数据库接口，将数据异步地写入磁盘，以便盘后分析。
4. 策略分析: 本项目基于一个简易的策略——均线策略，来进行预测与判断，并生成交易日志。

###  量化交易简介

量化交易[1](https://baike.baidu.com/item/量化交易/5266581)是指以先进的数学模型替代人为的主观判断，利用计算机技术从庞大的历史数据中海选能带来超额收益的多种“大概率”事件以制定策略，极大地减少了投资者情绪波动的影响，避免在市场极度狂热或悲观的情况下作出非理性的投资决策。

简单来说，量化交易就是通过一定的预测算法，预测股价走向，并代替人本身进行自动化的买入与卖出。同时由于计算机的参与，其在速度上相比于人工操作也有巨大的优势。

### 均线策略简介

为实现利益的最大化，优秀的预测模型与策略必不可少。在金融领域，已经产生了大量的模型与策略用于预测，如双均线策略、alpha对冲、日内回转交易、海龟交易法、机器学习等。

本次应用，我们使用了一个简易适合初学者的策略——均线策略。

经典的均线策略如下: 通过比较过去5天收盘平均值与过去20天收盘平均值，获取应执行的交易。如果5日均线大于20日均线，并且该股票当前没有持仓，则买入100手。如果5日均线小于20日均线，则该股票全部卖出。

在本次项目中，若记ma为近几十天平均值。当ma<sub>20</sub>>=ma<sub>5</sub>时认为该股票有下跌趋势，选择将该股票全部抛出，而当ma<sub>20</sub><ma<sub>5</sub>时认为该股票有上涨趋势，购入1 + round((ma<sub>5</sub>-ma<sub>20</sub>)*100)股。在本次测试中，由于我们无法实盘操作，我们暂时没有选择实盘操作，而是选择将交易日志存在本地`/root/ans.txt`。

### 数据获取

通过python的request库，从新浪财经实时地获取股票价格。为保证效率，使用线程池来实现多线程获取数据。从网页获取的数据格式如下：

获得的股票数据包含开盘价、交易量、竞买价、竞卖价、最高价、最低价、买一卖一报价、时间等大量信息，在本次测试中，我们仅使用股票名称、价格和获取时间。获取数据后，将此次监视股票池内所有股票的数据提交给处理模块。

相比于单线程轮询获取各支股票数据，多线程地获取股票数据有如下优势：

1. 提高系统的吞吐率。多线程编程使得一个进程中可以有多个并发(即同时进行)的操作。例如，当一个线程因为I/O操作而处于等待时，其他线程任然可以执行其操作。
2. 提高响应性。在使用多线程编程情况下，对于GUI软件(如桌面应用程序)而言，一个慢的操作(比如从服务器上下载一个大的文件)并不会导致软件的界面出现被“冻住”的现象而无法响应用户其他的操作；对与Web应用程序而言，一个请求慢了并不会影响其他请求处理。
3. 充分利用多核处理器资源。如今的多核处理器越来越普及，就算是手机这样的消费类设备也普片使用多核处理器。实施恰当的多线程编程有助于我们充分利用多核处理器资源，从而避免资源浪费。
4. 最小化对系统资源的使用。一个进程中的多个线程可以共享其所在进程所申请的资源(如内存空间)，因此使用多个线程相比于使用多个进程进行编程来说，节约了对系统资源的使用。
5. 简化程序的结构。线程可以简化复杂应用程序的结构。

在本次测试中，我们将使用Stock和Worker类来实现多线程数据获取。stock将会在初始化时，实现线程池的初始化，并指定将工作线程获取的数据提交给一个结果队列。此外，Stock还会进行线程的维护，保证所有线程均可正常工作。而每一个Worker实例都属于线程池中一部分，他们将不断执行Stock所提交的任务。待到本机监视的所有股票都从网页获取数据后，将所有结果放入，等待下一步处理。

### 结果展示

在测试中，我们启动了三个节点，监视若干支股票，并将交易信息存入ans.txt中。

运行时，可以很容易地通过rain 所提供的dashboard来监视节点的运行状况，可以查看到是否出现错误、是否结束运行等信息。

以下为运行过程中的节点状态。

![](files/workerstate1.png)

![](files/workerstate2.png) 

![](files/workerstate3.png)

![](files/workerstate4.png)
运行结束后，可以在指定目录下查看到数据库文件，数据库中存入了这段时间内的股票的所有数据信息。

![](files/tmpfiles.png)

以下为生成的交易信息的一部分。交易信息包含了详细时间、股票名称与买入卖出状态。BUY x表示购买了x单位的股票，SOLD x表示出售了x单位的股票（实际为清仓），WAIT表示什么都不做，继续观察。

```
2019-07-05,14:32:07,包钢股份  SOLD: 4
2019-07-05,14:32:08,中国平安 WAIT
2019-07-05,14:32:09,中原高速 WAIT
2019-07-05,14:32:09,深 赛 格  BUY: 1
2019-07-05,14:32:11,浦发银行  BUY: 1
2019-07-05,14:32:11,包钢股份 WAIT
2019-07-05,14:32:11,中国平安 WAIT
2019-07-05,14:32:12,中原高速 WAIT
2019-07-05,14:32:09,深 赛 格  BUY: 1
2019-07-05,14:32:14,浦发银行  BUY: 1
2019-07-05,14:32:14,包钢股份 WAIT
2019-07-05,14:32:14,中国平安 WAIT
2019-07-05,14:32:12,中原高速 WAIT
2019-07-05,14:32:18,深 赛 格  BUY: 1
2019-07-05,14:32:14,浦发银行  BUY: 1
2019-07-05,14:32:17,包钢股份 WAIT
2019-07-05,14:32:15,中国平安 WAIT
2019-07-05,14:32:15,中原高速 WAIT
2019-07-05,14:32:18,深 赛 格  BUY: 1
2019-07-05,14:32:17,浦发银行  BUY: 1
2019-07-05,14:32:17,包钢股份 WAIT
2019-07-05,14:32:17,中国平安 WAIT
2019-07-05,14:32:18,中原高速 WAIT
2019-07-05,14:32:21,深 赛 格  BUY: 1
2019-07-05,14:32:17,浦发银行  SOLD: 8
2019-07-05,14:32:20,包钢股份 WAIT
2019-07-05,14:32:17,中国平安 WAIT
2019-07-05,14:32:18,中原高速 WAIT
2019-07-05,14:32:24,深 赛 格  SOLD: 14
2019-07-05,14:32:20,浦发银行 WAIT
2019-07-05,14:32:23,包钢股份 WAIT
```

##  改进、展望与总结

### 目前项目存在的问题

1. rain分布式计算框架本身只提供python API，只能支持分发使用python编写的计算任务，泛用性不强。同时由于python进程与数据库进程间通讯方式单一，大量C支持的通讯方式（如消息队列，共享内存等）python均不支持，python与数据库交互速度仍不够快，交互过程不够优雅，存取数据时对实时性的影响较大，未能充分利用数据库实时性强的特点。
2. 数据库本身将实时性做到极致，但数据库易用性和功能性上仍有需要改进的地方。其功能相对单一，使用较为复杂，因此此项目所能提供的功能也极为有限。
3. 项目本身与用户的交互性不好。在量化交易中，用户只能通过dashboard查看节点运行状态，而无法获取节点所发出的具体交易信息，削弱了用户本身对交易状态的掌控。

### 展望与总结

我们希望能使用功能更加全面的分布式框架，对本项目进行改造。我们希望能对分布式计算能有更多的了解，从而能在现有基础上对框架进行改造，以提高项目本身的耦合性与泛用性以及效率。
